{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, in the entry form below, load in the file or files.**  First, take a look at your text.  An easy way to get started is to first read it in, and then run it through the sentence tokenizer to divide it up, even if this division is not fully accurate.  You may have to do a bit of work to figure out which will be the \"opening phrase\" that Wolfram Alpha shows.  Below, write the code to read in the text and split it into sentences, and then print out the **opening phrase**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True, there is existent more or less local interest in sec- tional history, and certain of the sons and daughters of the Middle States, alive to the importance of their section during the period ot colonization, have striven to perfect the historical records of their several States and to place a knowledge of them in the hands of the public.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = open('the_history_of_north_america.txt','r')\n",
    "raw = fp.read().replace('\\n', ' ')\n",
    "sents = sent_tokenizer.tokenize(raw)\n",
    "sents[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, tokenize.**  Look at the several dozen sentences to see what kind of tokenization issues you'll have.  Write a regular expression tokenizer, using the nltk.regexp_tokenize() as seen in class, or using something more sophisticated if you prefer, to do a nice job of breaking your text up into words.  You may need to make changes to the regex pattern that is given in the book to make it work well for your text collection. \n",
    "\n",
    "*How you break up the words will have effects down the line for how you can manipulate your text collection.  You may want to refine this code later.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'History',\n",
       " 'of',\n",
       " 'North',\n",
       " 'America',\n",
       " 'The',\n",
       " 'colonization',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Middle',\n",
       " 'States',\n",
       " 'Guy',\n",
       " 'Carleton',\n",
       " 'Lee',\n",
       " 'F.',\n",
       " 'N.',\n",
       " 'Thorpe',\n",
       " 'THE',\n",
       " 'HISTORY',\n",
       " 'OF',\n",
       " 'NORTH',\n",
       " 'AMERICA',\n",
       " 'VOLUME',\n",
       " 'FOUR',\n",
       " 'THE',\n",
       " 'COLONIZATION',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'MIDDLE',\n",
       " 'STATES',\n",
       " 'AND',\n",
       " 'MARTLAND',\n",
       " 'FREDERICK',\n",
       " 'ROBERTSON',\n",
       " 'JONES',\n",
       " 'Ph',\n",
       " 'D.',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'FACULTY',\n",
       " 'OF',\n",
       " 'RRYN',\n",
       " 'MAWR',\n",
       " 'COLLEGE',\n",
       " 'LATE',\n",
       " 'ASSISTANT',\n",
       " 'PROFESSOR',\n",
       " 'OF',\n",
       " 'HISTORY',\n",
       " 'AND',\n",
       " 'SOCIOLOGY',\n",
       " 'AT',\n",
       " 'UNION',\n",
       " 'COLLEGE',\n",
       " 'SCHENtCTADY',\n",
       " 'Author',\n",
       " 'of',\n",
       " 'th',\n",
       " 'History',\n",
       " 'of',\n",
       " 'Taxation',\n",
       " 'in',\n",
       " 'Connecticut',\n",
       " 'PRINTED',\n",
       " 'AND',\n",
       " 'PUBLISHED',\n",
       " 'FOR',\n",
       " 'Sl',\n",
       " 'BSCRIBERS',\n",
       " 'ONLY',\n",
       " 'BT',\n",
       " 'GEORGE',\n",
       " 'BARRIE',\n",
       " 'SONS',\n",
       " 'PHILADELPHIA',\n",
       " 'Copyright',\n",
       " '1904',\n",
       " 'by',\n",
       " 'George',\n",
       " 'Barrib',\n",
       " 'Sc',\n",
       " 'Soms',\n",
       " 'EDITOR',\n",
       " 'S',\n",
       " 'INTRODUCTION',\n",
       " 'Trb',\n",
       " 'history',\n",
       " 'of',\n",
       " 'Amefkftn',\n",
       " 'colonication',\n",
       " 'is',\n",
       " 'to',\n",
       " 'most',\n",
       " 'persons',\n",
       " 'the',\n",
       " 'record',\n",
       " 'of',\n",
       " 'the',\n",
       " 'activities',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Cavalier',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Furitani',\n",
       " 'Litde',\n",
       " 'thou',\n",
       " 't',\n",
       " 'is',\n",
       " 'given',\n",
       " 'to',\n",
       " 'the',\n",
       " 'story',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Dutchmen',\n",
       " 'who',\n",
       " 'strove',\n",
       " 'to',\n",
       " 'create',\n",
       " 'a',\n",
       " 'New',\n",
       " 'Netherland',\n",
       " 'or',\n",
       " 'to',\n",
       " 'that',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Swedes',\n",
       " 'who',\n",
       " 'wund',\n",
       " 'with',\n",
       " 'the',\n",
       " 'Dutch',\n",
       " 'and',\n",
       " 'dte',\n",
       " 'English',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Dela- ware',\n",
       " 'country',\n",
       " 'nor',\n",
       " 'indeed',\n",
       " 'is',\n",
       " 'much',\n",
       " 'general',\n",
       " 'interest',\n",
       " 'shown',\n",
       " 'in',\n",
       " 'the',\n",
       " 'accounts',\n",
       " 'of',\n",
       " 'the',\n",
       " 'foundation',\n",
       " 'of',\n",
       " 'New',\n",
       " 'Jetacj',\n",
       " 'Delawaie',\n",
       " 'or',\n",
       " 'Maryland',\n",
       " 'True',\n",
       " 'there',\n",
       " 'is',\n",
       " 'existent',\n",
       " 'more',\n",
       " 'or',\n",
       " 'less',\n",
       " 'local',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'sec- tional',\n",
       " 'history',\n",
       " 'and',\n",
       " 'certain',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sons',\n",
       " 'and',\n",
       " 'daughters',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Middle',\n",
       " 'States',\n",
       " 'alive',\n",
       " 'to',\n",
       " 'the',\n",
       " 'importance',\n",
       " 'of',\n",
       " 'their',\n",
       " 'section',\n",
       " 'during',\n",
       " 'the',\n",
       " 'period',\n",
       " 'ot',\n",
       " 'colonization',\n",
       " 'have',\n",
       " 'striven',\n",
       " 'to',\n",
       " 'perfect',\n",
       " 'the',\n",
       " 'historical',\n",
       " 'records',\n",
       " 'of',\n",
       " 'their',\n",
       " 'several',\n",
       " 'States',\n",
       " 'and',\n",
       " 'to',\n",
       " 'place',\n",
       " 'a',\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'them',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hands',\n",
       " 'of',\n",
       " 'the',\n",
       " 'public',\n",
       " 'But',\n",
       " 'when',\n",
       " 'wc',\n",
       " 'sum',\n",
       " 'up',\n",
       " 'this',\n",
       " 'local',\n",
       " 'interest',\n",
       " 'aad',\n",
       " 'its',\n",
       " 'effect',\n",
       " 'we',\n",
       " 'find',\n",
       " 'that',\n",
       " 'even',\n",
       " 'in',\n",
       " 'New',\n",
       " 'York',\n",
       " 'New',\n",
       " 'Jersey',\n",
       " 'Pennsylvania',\n",
       " 'Delaware',\n",
       " 'wd',\n",
       " 'Maryland',\n",
       " 'public',\n",
       " 'regard',\n",
       " 'tor',\n",
       " 'the',\n",
       " 'history',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'does',\n",
       " 'not',\n",
       " 'bulk',\n",
       " 'so',\n",
       " 'large',\n",
       " 'as',\n",
       " 'the',\n",
       " 'general',\n",
       " 'and',\n",
       " 'we',\n",
       " 'may',\n",
       " 't',\n",
       " 'gt',\n",
       " 'jr',\n",
       " 'popular',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hiftory',\n",
       " 'of',\n",
       " 'the',\n",
       " 'colonies',\n",
       " 'of',\n",
       " 'the',\n",
       " 'East',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'South',\n",
       " 'during',\n",
       " 'the',\n",
       " 'early',\n",
       " 'period',\n",
       " 'of',\n",
       " 'their',\n",
       " 'existence',\n",
       " 'n',\n",
       " 'therefoce',\n",
       " 'the',\n",
       " 'genenl',\n",
       " 'mder',\n",
       " 'consideii',\n",
       " 'this',\n",
       " 'period',\n",
       " 'oabncing',\n",
       " 'at',\n",
       " 'it',\n",
       " 'does',\n",
       " 'the',\n",
       " 'initial',\n",
       " 'years',\n",
       " 'of',\n",
       " 'American',\n",
       " 'coloniea- tioa',\n",
       " 'his',\n",
       " 'mind',\n",
       " 'fastens',\n",
       " 'more',\n",
       " 'often',\n",
       " 'upon',\n",
       " 'Pljrmouth',\n",
       " 'Rock',\n",
       " 'and',\n",
       " 'JuMMown',\n",
       " 'than',\n",
       " 'upon',\n",
       " 'Manhattan',\n",
       " 'and',\n",
       " 'St',\n",
       " 'Mafy',\n",
       " 's',\n",
       " 'and',\n",
       " 'when',\n",
       " 'he',\n",
       " 'studies',\n",
       " 'the',\n",
       " 'advanced',\n",
       " 'or',\n",
       " 'later',\n",
       " 'stage',\n",
       " 'of',\n",
       " 'the',\n",
       " 'period',\n",
       " 'of',\n",
       " 'colo- ittzation',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'to',\n",
       " 'New',\n",
       " 'Haven',\n",
       " 'New',\n",
       " 'Yoric',\n",
       " 'Philadelphia',\n",
       " 'gt',\n",
       " 'nd',\n",
       " 'Baltimore',\n",
       " 'that',\n",
       " 'he',\n",
       " 'tarns',\n",
       " 'but',\n",
       " 'to',\n",
       " 'Boston',\n",
       " 'and',\n",
       " 'Chariestoo',\n",
       " '1',\n",
       " 'MIDDLE',\n",
       " 'STATES',\n",
       " 'AND',\n",
       " 'MARTUUfD',\n",
       " 'Tbe',\n",
       " 'general',\n",
       " 'indifierence',\n",
       " 'to',\n",
       " 'mfttten',\n",
       " 'of',\n",
       " 'tecdonal',\n",
       " 'histoiy',\n",
       " 'is',\n",
       " 'it',\n",
       " 'is',\n",
       " 'happily',\n",
       " 'true',\n",
       " 'giving',\n",
       " 'way',\n",
       " 'before',\n",
       " 'the',\n",
       " 'efibits',\n",
       " 'of',\n",
       " 'such',\n",
       " 'learned',\n",
       " 'and',\n",
       " 'progressive',\n",
       " 'bodies',\n",
       " 'as',\n",
       " 'the',\n",
       " 'historical',\n",
       " 'societies',\n",
       " 'of',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Pennsylvania',\n",
       " 'and',\n",
       " 'Maryland',\n",
       " 'but',\n",
       " 'nevecthdess',\n",
       " 'the',\n",
       " 'bulk',\n",
       " 'of',\n",
       " 'the',\n",
       " 'people',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Middle',\n",
       " 'States',\n",
       " 'remain',\n",
       " 'as',\n",
       " 'unin- te',\n",
       " 'rested',\n",
       " 'as',\n",
       " 'were',\n",
       " 'the',\n",
       " 'bulk',\n",
       " 'of',\n",
       " 'the',\n",
       " 'people',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'in',\n",
       " 'the',\n",
       " 'stirring',\n",
       " 'events',\n",
       " 'of',\n",
       " 'their',\n",
       " 'history',\n",
       " 'in',\n",
       " 'the',\n",
       " 'unsur',\n",
       " 'passed',\n",
       " 'record',\n",
       " 'of',\n",
       " 'those',\n",
       " 'who',\n",
       " 'laid',\n",
       " 'surely',\n",
       " 'and',\n",
       " 'strongly',\n",
       " 'the',\n",
       " 'foundations',\n",
       " 'of',\n",
       " 'such',\n",
       " 'great',\n",
       " 'States',\n",
       " 'as',\n",
       " 'New',\n",
       " 'York',\n",
       " 'and',\n",
       " 'Feno- sylvania',\n",
       " 'It',\n",
       " 'is',\n",
       " 'difficult',\n",
       " 'to',\n",
       " 'assign',\n",
       " 'adequate',\n",
       " 'reason',\n",
       " 'for',\n",
       " 'such',\n",
       " 'attitude',\n",
       " 'on',\n",
       " 'the',\n",
       " 'part',\n",
       " 'of',\n",
       " 'those',\n",
       " 'who',\n",
       " 'may',\n",
       " 'well',\n",
       " 'be',\n",
       " 'ranked',\n",
       " 'among',\n",
       " 'the',\n",
       " 'most',\n",
       " 'progressive',\n",
       " 'and',\n",
       " 'intelligent',\n",
       " 'people',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'Wc',\n",
       " 'may',\n",
       " 'we',\n",
       " 'he',\n",
       " 'puzzled',\n",
       " 'as',\n",
       " 'to',\n",
       " 'a',\n",
       " 'solu',\n",
       " 'tion',\n",
       " 'of',\n",
       " 'our',\n",
       " 'perplexity',\n",
       " 'when',\n",
       " 'we',\n",
       " 'ask',\n",
       " 'ourselves',\n",
       " 'to',\n",
       " 'day',\n",
       " 'Can',\n",
       " 'any',\n",
       " 'section',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'boast',\n",
       " 'of',\n",
       " 'a',\n",
       " 'city',\n",
       " 'that',\n",
       " 'sur- passes',\n",
       " 'New',\n",
       " 'York',\n",
       " 'in',\n",
       " 'importance',\n",
       " 'or',\n",
       " 'of',\n",
       " 'four',\n",
       " 'cities',\n",
       " 'that',\n",
       " 'tum',\n",
       " 'ther',\n",
       " 'can',\n",
       " 'outrank',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Phil',\n",
       " 'Kl',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'hia',\n",
       " 'Pittsburg',\n",
       " 'and',\n",
       " 'Baitmiore',\n",
       " 'And',\n",
       " 'we',\n",
       " 'might',\n",
       " 'have',\n",
       " 'lt',\n",
       " 'kvd',\n",
       " 'urselves',\n",
       " 'in',\n",
       " 'the',\n",
       " 'period',\n",
       " 'of',\n",
       " 'State',\n",
       " 'buildinc',\n",
       " 'Does',\n",
       " 'any',\n",
       " 'stcnuii',\n",
       " 'possess',\n",
       " 'greater',\n",
       " 'aijd',\n",
       " 'w',\n",
       " 'c',\n",
       " 'ilrhier',\n",
       " 'town',\n",
       " 'ilian',\n",
       " 'that',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Middle',\n",
       " 'colonics',\n",
       " 'But',\n",
       " 'we',\n",
       " 'need',\n",
       " 'jiot',\n",
       " 'confine',\n",
       " 'our',\n",
       " 'questions',\n",
       " 'to',\n",
       " 'those',\n",
       " 'concerning',\n",
       " 'material',\n",
       " 'prosperity',\n",
       " 'Were',\n",
       " 'not',\n",
       " 'the',\n",
       " 'men',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Middle',\n",
       " 'colo- nies',\n",
       " 'the',\n",
       " 'peers',\n",
       " 'of',\n",
       " 'those',\n",
       " 'of',\n",
       " 'any',\n",
       " 'section',\n",
       " 'of',\n",
       " 'the',\n",
       " 'British',\n",
       " 'posses- sions',\n",
       " 'If',\n",
       " 'the',\n",
       " 'South',\n",
       " 'bad',\n",
       " 'Washington',\n",
       " 'the',\n",
       " 'Middle',\n",
       " 'colonics',\n",
       " 'bad',\n",
       " 'Fnmklin',\n",
       " 'if',\n",
       " 'the',\n",
       " 'South',\n",
       " 'spoke',\n",
       " 'of',\n",
       " 'Jefierson',\n",
       " 'the',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'mig',\n",
       " 't',\n",
       " 'well',\n",
       " 'boast',\n",
       " 'of',\n",
       " 'Hamilton',\n",
       " 'and',\n",
       " 'if',\n",
       " 'the',\n",
       " 'New',\n",
       " 'England',\n",
       " 'colonies',\n",
       " 'declared',\n",
       " 'the',\n",
       " 'fame',\n",
       " 'of',\n",
       " 'Adams',\n",
       " 'and',\n",
       " 'Han- cock',\n",
       " 'had',\n",
       " 'not',\n",
       " 'tbe',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'Jaj',\n",
       " 'and',\n",
       " 'Morris',\n",
       " 'i',\n",
       " 'and',\n",
       " 'Maiyland',\n",
       " 'was',\n",
       " 'not',\n",
       " 'behind',\n",
       " 'its',\n",
       " 'sister',\n",
       " 'colonies',\n",
       " 'in',\n",
       " 'the',\n",
       " 'possession',\n",
       " 'of',\n",
       " 'great',\n",
       " 'men',\n",
       " 'Did',\n",
       " 'New',\n",
       " 'England',\n",
       " 'or',\n",
       " 'the',\n",
       " 'South',\n",
       " 'possess',\n",
       " 'a',\n",
       " 'more',\n",
       " 'worthy',\n",
       " 'colonizer',\n",
       " 'than',\n",
       " 'William',\n",
       " 'Pennf',\n",
       " 'a',\n",
       " 'more',\n",
       " 'interest',\n",
       " 'compelling',\n",
       " 'figure',\n",
       " 'than',\n",
       " 'Peter',\n",
       " 'Stuyvesant',\n",
       " 'or',\n",
       " 'a',\n",
       " 'more',\n",
       " 'far',\n",
       " 'sighted',\n",
       " 'pro- j',\n",
       " 'prietor',\n",
       " 'than',\n",
       " 'Cecil',\n",
       " 'Calvert',\n",
       " 'Then',\n",
       " 'too',\n",
       " 'was',\n",
       " 'the',\n",
       " 'history',\n",
       " 'of',\n",
       " 'New',\n",
       " 'York',\n",
       " 'the',\n",
       " 'Jerseys',\n",
       " 'and',\n",
       " 'Pennsylvania',\n",
       " 'less',\n",
       " 'worthy',\n",
       " 'of',\n",
       " 'I',\n",
       " 'record',\n",
       " 'than',\n",
       " 'that',\n",
       " 'of',\n",
       " 'the',\n",
       " 'colonies',\n",
       " 'of',\n",
       " 'the',\n",
       " 'South',\n",
       " 'and',\n",
       " 'of',\n",
       " 'New',\n",
       " 'j',\n",
       " 'England',\n",
       " 'If',\n",
       " 'we',\n",
       " 'turn',\n",
       " 'to',\n",
       " 'Massachusetts',\n",
       " 'because',\n",
       " 'of',\n",
       " 'Lexington',\n",
       " 'I',\n",
       " 'i',\n",
       " 'EDITOR',\n",
       " 'S',\n",
       " 'INTRODUCrwN',\n",
       " 'diid',\n",
       " 'Concord',\n",
       " 'and',\n",
       " 'Lu',\n",
       " 'the',\n",
       " 'South',\n",
       " 'because',\n",
       " 'of',\n",
       " 'Yorktown',\n",
       " 'and',\n",
       " 'Cowpens',\n",
       " 'why',\n",
       " 'not',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'for',\n",
       " 'the',\n",
       " 'record',\n",
       " 'of',\n",
       " 'Ticonderogg',\n",
       " 'Saratoga',\n",
       " 'and',\n",
       " 'Valley',\n",
       " 'Forge',\n",
       " 'In',\n",
       " 'fact',\n",
       " 'in',\n",
       " 'nothing',\n",
       " 'were',\n",
       " 'the',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'mirpassed',\n",
       " 'by',\n",
       " 'those',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Northeast',\n",
       " 'and',\n",
       " 'the',\n",
       " 'South',\n",
       " 'What',\n",
       " 'then',\n",
       " 'is',\n",
       " 'the',\n",
       " 'reason',\n",
       " 'for',\n",
       " 'the',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'the',\n",
       " 'history',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Middle',\n",
       " 'States',\n",
       " 'which',\n",
       " 'stand',\n",
       " 'tonlay',\n",
       " 'as',\n",
       " 'did',\n",
       " 'their',\n",
       " 'forerunners',\n",
       " 'the',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'unsurpamed',\n",
       " 'in',\n",
       " 'men',\n",
       " 'and',\n",
       " 'resources',\n",
       " 'and',\n",
       " 'a',\n",
       " 'glorious',\n",
       " 'past',\n",
       " 'The',\n",
       " 'reply',\n",
       " 'seems',\n",
       " 'to',\n",
       " 'us',\n",
       " 'to',\n",
       " 'be',\n",
       " 'unmistakable',\n",
       " 'though',\n",
       " 'complex',\n",
       " 'The',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'and',\n",
       " 'States',\n",
       " 'though',\n",
       " 'always',\n",
       " 'earnest',\n",
       " 'and',\n",
       " 'resultful',\n",
       " 'in',\n",
       " 'action',\n",
       " 'have',\n",
       " 'been',\n",
       " 'slow',\n",
       " 'to',\n",
       " 'advertise',\n",
       " 'their',\n",
       " 'deeds',\n",
       " 'Then',\n",
       " 'too',\n",
       " 'inter- est',\n",
       " 'has',\n",
       " 'centred',\n",
       " 'in',\n",
       " 'the',\n",
       " 'South',\n",
       " 'and',\n",
       " 'in',\n",
       " 'New',\n",
       " 'England',\n",
       " 'The',\n",
       " 'South',\n",
       " 'separated',\n",
       " 'from',\n",
       " 'New',\n",
       " 'England',\n",
       " 'in',\n",
       " 'thought',\n",
       " 'and',\n",
       " 'action',\n",
       " 'was',\n",
       " 'the',\n",
       " 'land',\n",
       " 'of',\n",
       " 'Romance',\n",
       " 'this',\n",
       " 'attribution',\n",
       " 'coupled',\n",
       " 'with',\n",
       " 'the',\n",
       " 'notoriety',\n",
       " 'given',\n",
       " 'to',\n",
       " 'the',\n",
       " 'section',\n",
       " 'by',\n",
       " 'the',\n",
       " 'agitation',\n",
       " 'conccin- ing',\n",
       " 'its',\n",
       " 'peculiar',\n",
       " 'institution',\n",
       " 'the',\n",
       " 'character',\n",
       " 'of',\n",
       " 'Southern',\n",
       " 'IcadtTS',\n",
       " 'and',\n",
       " 'the',\n",
       " 'strength',\n",
       " 'and',\n",
       " 'success',\n",
       " 'with',\n",
       " 'which',\n",
       " 'they',\n",
       " 'maintained',\n",
       " 'any',\n",
       " 'position',\n",
       " 'assumed',\n",
       " 'by',\n",
       " 'them',\n",
       " 'combined',\n",
       " 'to',\n",
       " 'centre',\n",
       " 'attention',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'South',\n",
       " 'and',\n",
       " 'to',\n",
       " 'bring',\n",
       " 'the',\n",
       " 'section',\n",
       " 'into',\n",
       " 'disproportionate',\n",
       " 'prominence',\n",
       " 'The',\n",
       " 'South',\n",
       " 'however',\n",
       " 'differed',\n",
       " 'widely',\n",
       " 'from',\n",
       " 'New',\n",
       " 'England',\n",
       " 'in',\n",
       " 'that',\n",
       " 'its',\n",
       " 'praise',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'its',\n",
       " 'dispraise',\n",
       " 'came',\n",
       " 'from',\n",
       " 'those',\n",
       " 'not',\n",
       " 'of',\n",
       " 'its',\n",
       " 'soil',\n",
       " 'and',\n",
       " 'in',\n",
       " 'almost',\n",
       " 'every',\n",
       " 'instance',\n",
       " 'not',\n",
       " 'resident',\n",
       " 'within',\n",
       " 'its',\n",
       " 'borders',\n",
       " 'Because',\n",
       " 'of',\n",
       " 'this',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'local',\n",
       " 'panegyr- ists',\n",
       " 'it',\n",
       " 'is',\n",
       " 'second',\n",
       " 'to',\n",
       " 'New',\n",
       " 'England',\n",
       " 'in',\n",
       " 'the',\n",
       " 'attention',\n",
       " 'that',\n",
       " 'has',\n",
       " 'been',\n",
       " 'paid',\n",
       " 'to',\n",
       " 'its',\n",
       " 'history',\n",
       " 'in',\n",
       " 'special',\n",
       " 'and',\n",
       " 'general',\n",
       " 'works',\n",
       " 'upon',\n",
       " 'American',\n",
       " 'colonization',\n",
       " 'New',\n",
       " 'England',\n",
       " 'possessed',\n",
       " 'the',\n",
       " 'radicalism',\n",
       " 'of',\n",
       " 'the',\n",
       " 'South',\n",
       " 'with- out',\n",
       " 'her',\n",
       " 'picturesqiieness',\n",
       " 'Though',\n",
       " 'not',\n",
       " 'so',\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regex for normal word, numbers, and workds like \"colo* nies\", “sea- board”, \"1613-1647\", \"you're\"\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = nltk.RegexpTokenizer(r'(?:[A-Z]\\.)+|\\w+-+\\s\\w+|\\w+\\*+\\s\\w+|\\w+|\\d+|\\d+-\\d+|\\w+\\'\\w+')\n",
    "words = tokenizer.tokenize(raw)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute word counts.** Now compute your frequency distribution using a FreqDist over the words. Let's not do lowercasing or stemming yet.  You can run this over the whole collection together, or sentence by sentence. Write the code for computing the FreqDist below and show the most common 20 words that result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 13739),\n",
       " ('of', 8728),\n",
       " ('to', 5362),\n",
       " ('and', 5329),\n",
       " ('in', 3523),\n",
       " ('was', 3296),\n",
       " ('a', 2774),\n",
       " ('The', 1700),\n",
       " ('were', 1648),\n",
       " ('that', 1477),\n",
       " ('by', 1415),\n",
       " ('his', 1329),\n",
       " ('for', 1257),\n",
       " ('New', 1216),\n",
       " ('had', 1212),\n",
       " ('with', 1010),\n",
       " ('as', 964),\n",
       " ('he', 957),\n",
       " ('on', 946),\n",
       " ('at', 936)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_freqdist = nltk.FreqDist(words)\n",
    "mp_freqdist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize the text.** Now adjust the output by normalizing the text: things you can try include removing stopwords, removing very short words, lowercasing the text, improving the tokenization, and/or doing other adjustments to bring content words higher up in the results.  The goal is to dig deeper into the collection to find interesting but relatively frequent words.  Show the code for these changes below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['History',\n",
       " 'North',\n",
       " 'America',\n",
       " 'colonization',\n",
       " 'Middle',\n",
       " 'States',\n",
       " 'Guy',\n",
       " 'Carleton',\n",
       " 'Lee',\n",
       " 'F.',\n",
       " 'N.',\n",
       " 'Thorpe',\n",
       " 'HISTORY',\n",
       " 'NORTH',\n",
       " 'AMERICA',\n",
       " 'VOLUME',\n",
       " 'FOUR',\n",
       " 'COLONIZATION',\n",
       " 'MIDDLE',\n",
       " 'STATES',\n",
       " 'MARTLAND',\n",
       " 'FREDERICK',\n",
       " 'ROBERTSON',\n",
       " 'JONES',\n",
       " 'Ph',\n",
       " 'D.',\n",
       " 'FACULTY',\n",
       " 'RRYN',\n",
       " 'MAWR',\n",
       " 'COLLEGE',\n",
       " 'LATE',\n",
       " 'ASSISTANT',\n",
       " 'PROFESSOR',\n",
       " 'HISTORY',\n",
       " 'SOCIOLOGY',\n",
       " 'UNION',\n",
       " 'COLLEGE',\n",
       " 'SCHENtCTADY',\n",
       " 'Author',\n",
       " 'th',\n",
       " 'History',\n",
       " 'Taxation',\n",
       " 'Connecticut',\n",
       " 'PRINTED',\n",
       " 'PUBLISHED',\n",
       " 'Sl',\n",
       " 'BSCRIBERS',\n",
       " 'BT',\n",
       " 'GEORGE',\n",
       " 'BARRIE',\n",
       " 'SONS',\n",
       " 'PHILADELPHIA',\n",
       " 'Copyright',\n",
       " '1904',\n",
       " 'George',\n",
       " 'Barrib',\n",
       " 'Sc',\n",
       " 'Soms',\n",
       " 'EDITOR',\n",
       " 'INTRODUCTION',\n",
       " 'Trb',\n",
       " 'history',\n",
       " 'Amefkftn',\n",
       " 'colonication',\n",
       " 'persons',\n",
       " 'record',\n",
       " 'activities',\n",
       " 'Cavalier',\n",
       " 'Furitani',\n",
       " 'Litde',\n",
       " 'thou',\n",
       " 'given',\n",
       " 'story',\n",
       " 'Dutchmen',\n",
       " 'strove',\n",
       " 'create',\n",
       " 'New',\n",
       " 'Netherland',\n",
       " 'Swedes',\n",
       " 'wund',\n",
       " 'Dutch',\n",
       " 'dte',\n",
       " 'English',\n",
       " 'Delaware',\n",
       " 'country',\n",
       " 'indeed',\n",
       " 'much',\n",
       " 'general',\n",
       " 'interest',\n",
       " 'shown',\n",
       " 'accounts',\n",
       " 'foundation',\n",
       " 'New',\n",
       " 'Jetacj',\n",
       " 'Delawaie',\n",
       " 'Maryland',\n",
       " 'True',\n",
       " 'existent',\n",
       " 'less',\n",
       " 'local',\n",
       " 'interest',\n",
       " 'sectional',\n",
       " 'history',\n",
       " 'certain',\n",
       " 'sons',\n",
       " 'daughters',\n",
       " 'Middle',\n",
       " 'States',\n",
       " 'alive',\n",
       " 'importance',\n",
       " 'section',\n",
       " 'period',\n",
       " 'ot',\n",
       " 'colonization',\n",
       " 'striven',\n",
       " 'perfect',\n",
       " 'historical',\n",
       " 'records',\n",
       " 'several',\n",
       " 'States',\n",
       " 'place',\n",
       " 'knowledge',\n",
       " 'hands',\n",
       " 'public',\n",
       " 'wc',\n",
       " 'sum',\n",
       " 'local',\n",
       " 'interest',\n",
       " 'aad',\n",
       " 'effect',\n",
       " 'find',\n",
       " 'even',\n",
       " 'New',\n",
       " 'York',\n",
       " 'New',\n",
       " 'Jersey',\n",
       " 'Pennsylvania',\n",
       " 'Delaware',\n",
       " 'wd',\n",
       " 'Maryland',\n",
       " 'public',\n",
       " 'regard',\n",
       " 'tor',\n",
       " 'history',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'bulk',\n",
       " 'large',\n",
       " 'general',\n",
       " 'may',\n",
       " 'gt',\n",
       " 'jr',\n",
       " 'popular',\n",
       " 'interest',\n",
       " 'hiftory',\n",
       " 'colonies',\n",
       " 'East',\n",
       " 'South',\n",
       " 'early',\n",
       " 'period',\n",
       " 'existence',\n",
       " 'therefoce',\n",
       " 'genenl',\n",
       " 'mder',\n",
       " 'consideii',\n",
       " 'period',\n",
       " 'oabncing',\n",
       " 'initial',\n",
       " 'years',\n",
       " 'American',\n",
       " 'colonieatioa',\n",
       " 'mind',\n",
       " 'fastens',\n",
       " 'often',\n",
       " 'upon',\n",
       " 'Pljrmouth',\n",
       " 'Rock',\n",
       " 'JuMMown',\n",
       " 'upon',\n",
       " 'Manhattan',\n",
       " 'St',\n",
       " 'Mafy',\n",
       " 'studies',\n",
       " 'advanced',\n",
       " 'later',\n",
       " 'stage',\n",
       " 'period',\n",
       " 'coloittzation',\n",
       " 'New',\n",
       " 'New',\n",
       " 'Yoric',\n",
       " 'Philadelphia',\n",
       " 'gt',\n",
       " 'nd',\n",
       " 'Baltimore',\n",
       " 'tarns',\n",
       " 'Boston',\n",
       " 'Chariestoo',\n",
       " 'MIDDLE',\n",
       " 'STATES',\n",
       " 'MARTUUfD',\n",
       " 'Tbe',\n",
       " 'general',\n",
       " 'indifierence',\n",
       " 'mfttten',\n",
       " 'tecdonal',\n",
       " 'histoiy',\n",
       " 'happily',\n",
       " 'true',\n",
       " 'giving',\n",
       " 'way',\n",
       " 'efibits',\n",
       " 'learned',\n",
       " 'progressive',\n",
       " 'bodies',\n",
       " 'historical',\n",
       " 'societies',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Pennsylvania',\n",
       " 'Maryland',\n",
       " 'nevecthdess',\n",
       " 'bulk',\n",
       " 'people',\n",
       " 'Middle',\n",
       " 'States',\n",
       " 'remain',\n",
       " 'uninte',\n",
       " 'rested',\n",
       " 'bulk',\n",
       " 'people',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'stirring',\n",
       " 'events',\n",
       " 'history',\n",
       " 'unsur',\n",
       " 'passed',\n",
       " 'record',\n",
       " 'laid',\n",
       " 'surely',\n",
       " 'strongly',\n",
       " 'foundations',\n",
       " 'great',\n",
       " 'States',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Fenosylvania',\n",
       " 'difficult',\n",
       " 'assign',\n",
       " 'adequate',\n",
       " 'reason',\n",
       " 'attitude',\n",
       " 'part',\n",
       " 'may',\n",
       " 'well',\n",
       " 'ranked',\n",
       " 'among',\n",
       " 'progressive',\n",
       " 'intelligent',\n",
       " 'people',\n",
       " 'United',\n",
       " 'States',\n",
       " 'Wc',\n",
       " 'may',\n",
       " 'puzzled',\n",
       " 'solu',\n",
       " 'tion',\n",
       " 'perplexity',\n",
       " 'ask',\n",
       " 'day',\n",
       " 'section',\n",
       " 'United',\n",
       " 'States',\n",
       " 'boast',\n",
       " 'city',\n",
       " 'surpasses',\n",
       " 'New',\n",
       " 'York',\n",
       " 'importance',\n",
       " 'four',\n",
       " 'cities',\n",
       " 'tum',\n",
       " 'ther',\n",
       " 'outrank',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Phil',\n",
       " 'Kl',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'hia',\n",
       " 'Pittsburg',\n",
       " 'Baitmiore',\n",
       " 'might',\n",
       " 'lt',\n",
       " 'kvd',\n",
       " 'urselves',\n",
       " 'period',\n",
       " 'State',\n",
       " 'buildinc',\n",
       " 'stcnuii',\n",
       " 'possess',\n",
       " 'greater',\n",
       " 'aijd',\n",
       " 'ilrhier',\n",
       " 'town',\n",
       " 'ilian',\n",
       " 'Middle',\n",
       " 'colonics',\n",
       " 'need',\n",
       " 'jiot',\n",
       " 'confine',\n",
       " 'questions',\n",
       " 'concerning',\n",
       " 'material',\n",
       " 'prosperity',\n",
       " 'men',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'peers',\n",
       " 'section',\n",
       " 'British',\n",
       " 'possessions',\n",
       " 'South',\n",
       " 'bad',\n",
       " 'Washington',\n",
       " 'Middle',\n",
       " 'colonics',\n",
       " 'bad',\n",
       " 'Fnmklin',\n",
       " 'South',\n",
       " 'spoke',\n",
       " 'Jefierson',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'mig',\n",
       " 'well',\n",
       " 'boast',\n",
       " 'Hamilton',\n",
       " 'New',\n",
       " 'England',\n",
       " 'colonies',\n",
       " 'declared',\n",
       " 'fame',\n",
       " 'Adams',\n",
       " 'Hancock',\n",
       " 'tbe',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'Jaj',\n",
       " 'Morris',\n",
       " 'Maiyland',\n",
       " 'behind',\n",
       " 'sister',\n",
       " 'colonies',\n",
       " 'possession',\n",
       " 'great',\n",
       " 'men',\n",
       " 'New',\n",
       " 'England',\n",
       " 'South',\n",
       " 'possess',\n",
       " 'worthy',\n",
       " 'colonizer',\n",
       " 'William',\n",
       " 'Pennf',\n",
       " 'interest',\n",
       " 'compelling',\n",
       " 'figure',\n",
       " 'Peter',\n",
       " 'Stuyvesant',\n",
       " 'far',\n",
       " 'sighted',\n",
       " 'proj',\n",
       " 'prietor',\n",
       " 'Cecil',\n",
       " 'Calvert',\n",
       " 'history',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Jerseys',\n",
       " 'Pennsylvania',\n",
       " 'less',\n",
       " 'worthy',\n",
       " 'record',\n",
       " 'colonies',\n",
       " 'South',\n",
       " 'New',\n",
       " 'England',\n",
       " 'turn',\n",
       " 'Massachusetts',\n",
       " 'Lexington',\n",
       " 'EDITOR',\n",
       " 'INTRODUCrwN',\n",
       " 'diid',\n",
       " 'Concord',\n",
       " 'Lu',\n",
       " 'South',\n",
       " 'Yorktown',\n",
       " 'Cowpens',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'record',\n",
       " 'Ticonderogg',\n",
       " 'Saratoga',\n",
       " 'Valley',\n",
       " 'Forge',\n",
       " 'fact',\n",
       " 'nothing',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'mirpassed',\n",
       " 'Northeast',\n",
       " 'South',\n",
       " 'reason',\n",
       " 'lack',\n",
       " 'interest',\n",
       " 'history',\n",
       " 'Middle',\n",
       " 'States',\n",
       " 'stand',\n",
       " 'tonlay',\n",
       " 'forerunners',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'unsurpamed',\n",
       " 'men',\n",
       " 'resources',\n",
       " 'glorious',\n",
       " 'past',\n",
       " 'reply',\n",
       " 'seems',\n",
       " 'us',\n",
       " 'unmistakable',\n",
       " 'though',\n",
       " 'complex',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'States',\n",
       " 'though',\n",
       " 'always',\n",
       " 'earnest',\n",
       " 'resultful',\n",
       " 'action',\n",
       " 'slow',\n",
       " 'advertise',\n",
       " 'deeds',\n",
       " 'interest',\n",
       " 'centred',\n",
       " 'South',\n",
       " 'New',\n",
       " 'England',\n",
       " 'South',\n",
       " 'separated',\n",
       " 'New',\n",
       " 'England',\n",
       " 'thought',\n",
       " 'action',\n",
       " 'land',\n",
       " 'Romance',\n",
       " 'attribution',\n",
       " 'coupled',\n",
       " 'notoriety',\n",
       " 'given',\n",
       " 'section',\n",
       " 'agitation',\n",
       " 'conccining',\n",
       " 'peculiar',\n",
       " 'institution',\n",
       " 'character',\n",
       " 'Southern',\n",
       " 'IcadtTS',\n",
       " 'strength',\n",
       " 'success',\n",
       " 'maintained',\n",
       " 'position',\n",
       " 'assumed',\n",
       " 'combined',\n",
       " 'centre',\n",
       " 'attention',\n",
       " 'upon',\n",
       " 'South',\n",
       " 'bring',\n",
       " 'section',\n",
       " 'disproportionate',\n",
       " 'prominence',\n",
       " 'South',\n",
       " 'however',\n",
       " 'differed',\n",
       " 'widely',\n",
       " 'New',\n",
       " 'England',\n",
       " 'praise',\n",
       " 'well',\n",
       " 'dispraise',\n",
       " 'came',\n",
       " 'soil',\n",
       " 'almost',\n",
       " 'every',\n",
       " 'instance',\n",
       " 'resident',\n",
       " 'within',\n",
       " 'borders',\n",
       " 'lack',\n",
       " 'local',\n",
       " 'panegyrists',\n",
       " 'second',\n",
       " 'New',\n",
       " 'England',\n",
       " 'attention',\n",
       " 'paid',\n",
       " 'history',\n",
       " 'special',\n",
       " 'general',\n",
       " 'works',\n",
       " 'upon',\n",
       " 'American',\n",
       " 'colonization',\n",
       " 'New',\n",
       " 'England',\n",
       " 'possessed',\n",
       " 'radicalism',\n",
       " 'South',\n",
       " 'without',\n",
       " 'picturesqiieness',\n",
       " 'Though',\n",
       " 'rich',\n",
       " 'natural',\n",
       " 'resources',\n",
       " 'filled',\n",
       " 'spirit',\n",
       " 'endeavor',\n",
       " 'radicalism',\n",
       " 'rrsoiirces',\n",
       " 'progressiveness',\n",
       " 'would',\n",
       " 'given',\n",
       " 'New',\n",
       " 'England',\n",
       " 'historical',\n",
       " 'prominence',\n",
       " 'possessed',\n",
       " 'scores',\n",
       " 'authors',\n",
       " 'speakers',\n",
       " 'season',\n",
       " 'season',\n",
       " 'sounded',\n",
       " 'praises',\n",
       " 'section',\n",
       " 'leaders',\n",
       " 'Traditions',\n",
       " 'period',\n",
       " 'New',\n",
       " 'England',\n",
       " 'colonization',\n",
       " 'made',\n",
       " 'basis',\n",
       " 'Yiii',\n",
       " 'MIDDLE',\n",
       " 'STATES',\n",
       " 'UAETLAND',\n",
       " 'numberless',\n",
       " 'publications',\n",
       " 'Literary',\n",
       " 'industry',\n",
       " 'abilitjr',\n",
       " 'magnified',\n",
       " 'importance',\n",
       " 'New',\n",
       " 'England',\n",
       " 'creation',\n",
       " 'progress',\n",
       " 'United',\n",
       " 'States',\n",
       " 'made',\n",
       " 'histor',\n",
       " 'New',\n",
       " 'England',\n",
       " 'household',\n",
       " 'word',\n",
       " 'section',\n",
       " 'discussed',\n",
       " 'South',\n",
       " 'iMiddle',\n",
       " 'States',\n",
       " 'local',\n",
       " 'history',\n",
       " 'recent',\n",
       " 'years',\n",
       " 'slightly',\n",
       " 'studied',\n",
       " 'generally',\n",
       " 'Icnown',\n",
       " 'result',\n",
       " 'country',\n",
       " 'familiar',\n",
       " 'history',\n",
       " 'Puritan',\n",
       " 'thev',\n",
       " 'ho',\n",
       " 'know',\n",
       " 'history',\n",
       " 'Quaker',\n",
       " 'sturdy',\n",
       " 'culonists',\n",
       " 'vvhu',\n",
       " 'fuliowed',\n",
       " 'Dutch',\n",
       " 'Hudson',\n",
       " 'brought',\n",
       " 'naught',\n",
       " 'plans',\n",
       " 'Calvert',\n",
       " 'paiticularization',\n",
       " 'section',\n",
       " 'unfortunate',\n",
       " 'foundation',\n",
       " 'Boston',\n",
       " 'impoitant',\n",
       " 'New',\n",
       " 'York',\n",
       " 'New',\n",
       " 'basis',\n",
       " 'history',\n",
       " 'Baltimore',\n",
       " 'Massachusetts',\n",
       " 'daim',\n",
       " 'upon',\n",
       " 'attention',\n",
       " 'Pennsjlvaman',\n",
       " 'much',\n",
       " 'Pennsylvanu',\n",
       " 'Citdaware',\n",
       " 'New',\n",
       " 'Jersey',\n",
       " 'profitable',\n",
       " 'historical',\n",
       " 'study',\n",
       " 'native',\n",
       " 'New',\n",
       " 'York',\n",
       " 'record',\n",
       " 'growth',\n",
       " 'Bute',\n",
       " 'fact',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'much',\n",
       " 'claim',\n",
       " 'general',\n",
       " 'study',\n",
       " 'communities',\n",
       " '1776',\n",
       " 'fringed',\n",
       " 'Atlantic',\n",
       " 'seaboard',\n",
       " 'men',\n",
       " 'Middle',\n",
       " 'colonies',\n",
       " 'left',\n",
       " 'deeds',\n",
       " 'related',\n",
       " 'others',\n",
       " 'ivcn',\n",
       " 'heart',\n",
       " 'task',\n",
       " 'men',\n",
       " 'laid',\n",
       " 'foundations',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Pennsylvania',\n",
       " 'Maryland',\n",
       " 'New',\n",
       " 'Jersey',\n",
       " 'Delaware',\n",
       " 'busy',\n",
       " 'personal',\n",
       " 'work',\n",
       " 'busy',\n",
       " 'labor',\n",
       " 'advancing',\n",
       " 'colonial',\n",
       " 'later',\n",
       " 'national',\n",
       " 'interests',\n",
       " 'spread',\n",
       " 'abroad',\n",
       " 'praise',\n",
       " 'contest',\n",
       " 'neighbors',\n",
       " 'south',\n",
       " 'east',\n",
       " 'control',\n",
       " 'place',\n",
       " 'descendants',\n",
       " 'colonists',\n",
       " 'great',\n",
       " 'measure',\n",
       " 'followed',\n",
       " 'example',\n",
       " 'tfaeur',\n",
       " 'ancestors',\n",
       " 'must',\n",
       " 'understood',\n",
       " 'disparaging',\n",
       " 'work',\n",
       " 'historical',\n",
       " 'students',\n",
       " 'Middle',\n",
       " 'States',\n",
       " 'claims',\n",
       " 'serious',\n",
       " 'attention',\n",
       " 'high',\n",
       " 'praise',\n",
       " 'though',\n",
       " 'scholarly',\n",
       " 'work',\n",
       " 'aroused',\n",
       " 'popular',\n",
       " 'interest',\n",
       " 'created',\n",
       " 'work',\n",
       " 'men',\n",
       " 'New',\n",
       " 'England',\n",
       " 'neither',\n",
       " 'spread',\n",
       " 'abroad',\n",
       " 'fame',\n",
       " 'Middle',\n",
       " 'cdbniet',\n",
       " 'EDITOR',\n",
       " 'JNtRODUCriON',\n",
       " 'aft',\n",
       " 'fame',\n",
       " 'New',\n",
       " 'England',\n",
       " 'tbe',\n",
       " 'South',\n",
       " 'di8',\n",
       " 'seminated',\n",
       " 'nation',\n",
       " 'world',\n",
       " 'day',\n",
       " 'signs',\n",
       " 'revival',\n",
       " 'interest',\n",
       " 'histoij',\n",
       " 'colonization',\n",
       " 'Middle',\n",
       " 'States',\n",
       " 'Readers',\n",
       " 'turning',\n",
       " 'record',\n",
       " 'thef',\n",
       " 'search',\n",
       " 'find',\n",
       " 'literature',\n",
       " 'colonization',\n",
       " 'period',\n",
       " 'scantyTht',\n",
       " 'rc',\n",
       " 'seems',\n",
       " 'lacking',\n",
       " 'work',\n",
       " 'gives',\n",
       " 'detailed',\n",
       " 'comprehensive',\n",
       " 'readable',\n",
       " 'descripticMi',\n",
       " 'colonization',\n",
       " 'period',\n",
       " 'terntory',\n",
       " 'created',\n",
       " 'states',\n",
       " 'New',\n",
       " 'York',\n",
       " 'New',\n",
       " 'Jersey',\n",
       " 'Delaware',\n",
       " 'Pennsylvania',\n",
       " 'Maryland',\n",
       " 'view',\n",
       " 'fact',\n",
       " 'plan',\n",
       " 'History',\n",
       " 'North',\n",
       " 'America',\n",
       " 'allowed',\n",
       " 'gi',\n",
       " 'crous',\n",
       " 'space',\n",
       " 'pcrioU',\n",
       " 'Co',\n",
       " 'onlzntiori',\n",
       " 'Ahudii',\n",
       " 'SiuUj',\n",
       " 'und',\n",
       " 'Marylandy',\n",
       " 'present',\n",
       " 'volume',\n",
       " 'result',\n",
       " 'Professor',\n",
       " 'Frederick',\n",
       " 'Robertson',\n",
       " 'Jones',\n",
       " 'iu',\n",
       " 'author',\n",
       " 'mass',\n",
       " 'available',\n",
       " 'source',\n",
       " 'material',\n",
       " 'succeeded',\n",
       " 'preparing',\n",
       " 'sympathetic',\n",
       " 'comprehensive',\n",
       " 'study',\n",
       " 'subject',\n",
       " 'volume',\n",
       " 'approach',\n",
       " 'ideal',\n",
       " 'schohrly',\n",
       " 'readable',\n",
       " 'history',\n",
       " 'presenting',\n",
       " 'succinct',\n",
       " 'form',\n",
       " 'wealth',\n",
       " 'detail',\n",
       " 'Guv',\n",
       " 'Carletok',\n",
       " 'Jtbng',\n",
       " 'Htpkim',\n",
       " 'Unhersity',\n",
       " 'AUTHOR',\n",
       " 'PREFACE',\n",
       " 'Arc',\n",
       " 'oRDTvn',\n",
       " 'charter',\n",
       " 'great',\n",
       " 'joint',\n",
       " 'stock',\n",
       " 'company',\n",
       " 'granted',\n",
       " 'James',\n",
       " '1606',\n",
       " 'jurisdiction',\n",
       " 'London',\n",
       " 'branch',\n",
       " 'Virginia',\n",
       " 'Company',\n",
       " 'extend',\n",
       " 'thirty',\n",
       " 'four',\n",
       " 'forty',\n",
       " 'one',\n",
       " 'degrees',\n",
       " 'north',\n",
       " 'latitude',\n",
       " 'Plymouth',\n",
       " 'branch',\n",
       " 'North',\n",
       " 'Virginia',\n",
       " 'Company',\n",
       " 'stretch',\n",
       " 'forty',\n",
       " 'five',\n",
       " 'thirtv',\n",
       " 'eieht',\n",
       " 'degrees',\n",
       " 'region',\n",
       " 'tliirty',\n",
       " 'eightii',\n",
       " 'aiui',\n",
       " 'tiie',\n",
       " 'tuity',\n",
       " 'first',\n",
       " 'parallels',\n",
       " 'thus',\n",
       " 'open',\n",
       " 'colonization',\n",
       " 'companies',\n",
       " 'stipiUatioti',\n",
       " 'neither',\n",
       " 'company',\n",
       " 'establish',\n",
       " 'settlement',\n",
       " 'within',\n",
       " 'one',\n",
       " 'hundred',\n",
       " 'English',\n",
       " 'miles',\n",
       " 'previous',\n",
       " 'settlement',\n",
       " 'made',\n",
       " 'Roughly',\n",
       " 'speaking',\n",
       " 'domain',\n",
       " 'included',\n",
       " 'part',\n",
       " 'Atlantic',\n",
       " 'seaboard',\n",
       " 'extending',\n",
       " 'latitude',\n",
       " 'extreme',\n",
       " 'southern',\n",
       " 'boun',\n",
       " 'dary',\n",
       " 'Maryland',\n",
       " 'thirty',\n",
       " 'seven',\n",
       " 'degrees',\n",
       " 'fifty',\n",
       " 'three',\n",
       " 'minutes',\n",
       " 'southernmost',\n",
       " 'boundary',\n",
       " 'Connecticut',\n",
       " 'fortyone',\n",
       " 'degrees',\n",
       " 'colonial',\n",
       " 'settlements',\n",
       " 'importance',\n",
       " 'within',\n",
       " 'present',\n",
       " 'jurisdiction',\n",
       " 'Middle',\n",
       " 'States',\n",
       " 'Maryland',\n",
       " 'approximately',\n",
       " 'within',\n",
       " 'limits',\n",
       " 'towns',\n",
       " 'villages',\n",
       " 'situated',\n",
       " 'Hudson',\n",
       " 'Mohawk',\n",
       " 'valleys',\n",
       " 'extreme',\n",
       " 'eastern',\n",
       " 'end',\n",
       " 'Long',\n",
       " 'Island',\n",
       " 'Albany',\n",
       " 'Schenectady',\n",
       " 'sopus',\n",
       " 'Southold',\n",
       " 'consequence',\n",
       " 'colonial',\n",
       " 'period',\n",
       " 'historv',\n",
       " 'Middle',\n",
       " 'States',\n",
       " 'Maryland',\n",
       " 'thus',\n",
       " 'identical',\n",
       " 'part',\n",
       " 'account',\n",
       " 'development',\n",
       " 'belt',\n",
       " 'debatable',\n",
       " 'land',\n",
       " 'colonies',\n",
       " 'within',\n",
       " 'zone',\n",
       " 'since',\n",
       " 'lay',\n",
       " 'New',\n",
       " 'England',\n",
       " 'north',\n",
       " 'east',\n",
       " 'Virginia',\n",
       " 'MIDDLE',\n",
       " 'STJTSS',\n",
       " 'MARTLAND',\n",
       " 'south',\n",
       " 'greatly',\n",
       " 'influenced',\n",
       " 'religious',\n",
       " 'political',\n",
       " 'social',\n",
       " 'economic',\n",
       " 'institutions',\n",
       " 'sections',\n",
       " 'Territorial',\n",
       " 'proximity',\n",
       " 'one',\n",
       " 'resulted',\n",
       " 'dominance',\n",
       " 'characteristic',\n",
       " 'institutions',\n",
       " 'neighboring',\n",
       " 'colonies',\n",
       " 'Maryland',\n",
       " 'responded',\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "adjust_words =[]\n",
    "for w in words:\n",
    "    # remove stop words and word less than 1 character\n",
    "    if (w.lower() not in stopwords.words('english')) and (len(w) > 1):\n",
    "        # adjust words that are sepeated in two lines, e.g. \"expedi- tion\" to \"expedition\" or \"In* dians\" to \"Indians\"\n",
    "        if re.findall(r'\\w+[-|\\*][\\s+]+\\w+|\\d+\\s+\\d+', w):\n",
    "            adjust_words.append(w.replace('- ','').replace('* ', ''))\n",
    "        else:\n",
    "            adjust_words.append(w)\n",
    "adjust_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show adjusted word counts.** Show the most frequent 20 words that result from these adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('New', 1216),\n",
       " ('Dutch', 525),\n",
       " ('York', 420),\n",
       " ('England', 399),\n",
       " ('upon', 392),\n",
       " ('English', 392),\n",
       " ('made', 390),\n",
       " ('one', 386),\n",
       " ('Assembly', 335),\n",
       " ('governor', 332),\n",
       " ('two', 315),\n",
       " ('time', 311),\n",
       " ('first', 290),\n",
       " ('would', 275),\n",
       " ('colonies', 274),\n",
       " ('province', 274),\n",
       " ('people', 253),\n",
       " ('Jersey', 246),\n",
       " ('government', 243),\n",
       " ('could', 236)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjust_mp_freqdist = nltk.FreqDist(adjust_words)\n",
    "adjust_mp_freqdist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a table.**\n",
    "Python provides an easy way to line columns up in a table.  You can specify a width for a string such as %6s, producing a string that is padded to width 6. It is right-justified by default, but a minus sign in front of it switches it to left-justified, so -3d% means left justify an integer with width 3.  *AND* if you don't know the width in advance, you can make it a variable by using an asterisk rather than a number before the '\\*s%' or the '-\\*d%'.  Check out this example (this is just fyi):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info type        Value           \n",
      "number of words  100000          \n"
     ]
    }
   ],
   "source": [
    "print('%-16s' % 'Info type', '%-16s' % 'Value')\n",
    "print('%-16s' % 'number of words', '%-16d' % 100000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Properties Table** Next there is a table of word properties, which you should compute (skip unique word stems, since we will do stemming in class on Wed).  Make a table that prints out:\n",
    "1. number of words\n",
    "2. number of unique words\n",
    "3. average word length\n",
    "4. longest word\n",
    "\n",
    "You can make your table look prettier than the example I showed above if you like! (If you already know pandas, you can use that.)\n",
    "\n",
    "You can decide for yourself if you want to eliminate punctuation and function words (stop words) or not.  It's your collection!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------------+----------------------------------------------------+\n",
      "|    | Property               | Value                                              |\n",
      "+====+========================+====================================================+\n",
      "|  0 | Number of Words        | 95334                                              |\n",
      "+----+------------------------+----------------------------------------------------+\n",
      "|  1 | Number of Unique Words | 20389                                              |\n",
      "+----+------------------------+----------------------------------------------------+\n",
      "|  2 | Average Word Length    | 6.477468689030147                                  |\n",
      "+----+------------------------+----------------------------------------------------+\n",
      "|  3 | Longest Word           | ['unfairnessFurthermore', 'wasooDftittttedfandon'] |\n",
      "+----+------------------------+----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "number_of_words = len(adjust_words)\n",
    "number_of_unique_words = len(set(adjust_words))\n",
    "average_word_length = sum([len(w) for w in adjust_words]) / number_of_words\n",
    "maxlen = max(len(w) for w in adjust_words)\n",
    "longest_words = [w for w in adjust_words if len(w) == maxlen]\n",
    "\n",
    "df = pd.DataFrame({'Property' : [\"Number of Words\", \"Number of Unique Words\" , \"Average Word Length\", \"Longest Word\"],\n",
    "                   'Value' : [number_of_words, number_of_unique_words, average_word_length, longest_words]})\n",
    "print(tabulate(df, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most Frequent Words List.** Next is the most frequent words list.  This table shows the percent of the total as well as the most frequent words, so compute this number as well.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------------+\n",
      "|    |   Percent | Words      |\n",
      "+====+===========+============+\n",
      "|  0 |  1.27552  | New        |\n",
      "+----+-----------+------------+\n",
      "|  1 |  0.550695 | Dutch      |\n",
      "+----+-----------+------------+\n",
      "|  2 |  0.440556 | York       |\n",
      "+----+-----------+------------+\n",
      "|  3 |  0.418529 | England    |\n",
      "+----+-----------+------------+\n",
      "|  4 |  0.411186 | upon       |\n",
      "+----+-----------+------------+\n",
      "|  5 |  0.411186 | English    |\n",
      "+----+-----------+------------+\n",
      "|  6 |  0.409088 | made       |\n",
      "+----+-----------+------------+\n",
      "|  7 |  0.404892 | one        |\n",
      "+----+-----------+------------+\n",
      "|  8 |  0.351396 | Assembly   |\n",
      "+----+-----------+------------+\n",
      "|  9 |  0.348249 | governor   |\n",
      "+----+-----------+------------+\n",
      "| 10 |  0.330417 | two        |\n",
      "+----+-----------+------------+\n",
      "| 11 |  0.326221 | time       |\n",
      "+----+-----------+------------+\n",
      "| 12 |  0.304194 | first      |\n",
      "+----+-----------+------------+\n",
      "| 13 |  0.28846  | would      |\n",
      "+----+-----------+------------+\n",
      "| 14 |  0.287411 | colonies   |\n",
      "+----+-----------+------------+\n",
      "| 15 |  0.287411 | province   |\n",
      "+----+-----------+------------+\n",
      "| 16 |  0.265383 | people     |\n",
      "+----+-----------+------------+\n",
      "| 17 |  0.25804  | Jersey     |\n",
      "+----+-----------+------------+\n",
      "| 18 |  0.254893 | government |\n",
      "+----+-----------+------------+\n",
      "| 19 |  0.247551 | could      |\n",
      "+----+-----------+------------+\n"
     ]
    }
   ],
   "source": [
    "most_percent = []\n",
    "most_words = []\n",
    "for w, f in adjust_mp_freqdist.most_common(20):\n",
    "    most_words.append(w)\n",
    "    most_percent.append(f * 100/number_of_words)\n",
    "\n",
    "df2 = pd.DataFrame({'Words' : most_words,\n",
    "                   'Percent' : most_percent})\n",
    "print(tabulate(df2, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most Frequent Capitalized Words List** We haven't lower-cased the text so you should be able to compute this. Don't worry about whether capitalization comes from proper nouns, start of sentences, or elsewhere. You need to make a different FreqDist to do this one.  Write the code here for the new FreqDist and the List itself.  Show the list here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MIDDLE', 196),\n",
       " ('STATES', 160),\n",
       " ('MARYLAND', 104),\n",
       " ('DUTCH', 50),\n",
       " ('II', 45),\n",
       " ('MARTLAND', 26),\n",
       " ('I.', 26),\n",
       " ('CHAPTER', 22),\n",
       " ('MARTUND', 19),\n",
       " ('JND', 18),\n",
       " ('STJTSS', 17),\n",
       " ('CONGEST', 16),\n",
       " ('RULE', 15),\n",
       " ('XIV', 15),\n",
       " ('III', 15),\n",
       " ('NEW', 14),\n",
       " ('AHD', 12),\n",
       " ('LORD', 12),\n",
       " ('IL', 12),\n",
       " ('ENGUSH', 11)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitalized_adjust_words = [w for w in adjust_words if w.isupper()]\n",
    "captitalized_adjust_mp_freqdist = nltk.FreqDist(capitalized_adjust_words)\n",
    "captitalized_adjust_mp_freqdist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentence Properties Table** This summarizes number of sentences and average sentence length in words and characters (you decide if you want to include stopwords/punctuation or not).  Print those out in a table here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------------------+-----------+\n",
      "|    | Property                              |     Value |\n",
      "+====+=======================================+===========+\n",
      "|  0 | Number of Senetences                  | 8608      |\n",
      "+----+---------------------------------------+-----------+\n",
      "|  1 | Average Sentence Length in Words      |   21.1285 |\n",
      "+----+---------------------------------------+-----------+\n",
      "|  2 | Average Sentence Length in Characters |  123.261  |\n",
      "+----+---------------------------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "adjust_sents =  [sent.strip() for sent in sents]\n",
    "number_of_sents = len(adjust_sents)\n",
    "\n",
    "sum_of_words_in_sentence = 0\n",
    "for sent in adjust_sents:\n",
    "    tokenizer1 = nltk.RegexpTokenizer('\\w+|\\w-\\s*\\w')  # This regular expresssion should be revised\n",
    "    words_in_sents = tokenizer1.tokenize(sent)\n",
    "    sum_of_words_in_sentence += len(words_in_sents)\n",
    "\n",
    "average_number_words_in_sents = sum_of_words_in_sentence / number_of_sents\n",
    "\n",
    "average_number_characters_in_sents = sum(len(w) for w in adjust_sents ) / number_of_sents\n",
    "\n",
    "df3 = pd.DataFrame({'Property' : ['Number of Senetences', 'Average Sentence Length in Words', 'Average Sentence Length in Characters'],\n",
    "                   'Value' :[number_of_sents, average_number_words_in_sents, average_number_characters_in_sents]})\n",
    "print(tabulate(df3, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflect on the Output** (Write a brief paragraph below answering these questions.) What does it tell you about your collection?  What does it fail to tell you?  How does your collection perhaps differ from others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "My collection is some kind of narrative story that contains an average 21 words in a single sentence, which I think it may a little bit longer than other books. And the average characters in a word may be around 6. From the most common word, it is obviously about the history and countries.\n",
    "\n",
    "The statics of longest word is \"unfairnessFurthermore\", \"wasooDftittttedfandon\", which I think are spelling errors after I checked the origin text. Based on oddities from words counts and raw text, I can tell this text is scanned from printed version.\n",
    "\n",
    "However, the statistics does not tell me the aveage sentences that may form a paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare to Your Partner's Collection** Now do the same analysis on your partner's adopted text.  \n",
    "Reflect on the similarities to or differences from your text collection. Also, talk with your partner to see how you approached *their* text differently. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------------+--------------------------------------------------------------------------------------+\n",
      "|    | Property               | Value                                                                                |\n",
      "+====+========================+======================================================================================+\n",
      "|  0 | Number of Words        | 183753                                                                               |\n",
      "+----+------------------------+--------------------------------------------------------------------------------------+\n",
      "|  1 | Number of Unique Words | 11164                                                                                |\n",
      "+----+------------------------+--------------------------------------------------------------------------------------+\n",
      "|  2 | Average Word Length    | 6.577138876644191                                                                    |\n",
      "+----+------------------------+--------------------------------------------------------------------------------------+\n",
      "|  3 | Longest Word           | ['dishonourableness', 'plenipotentiaries', 'contradistinction', 'misrepresentation'] |\n",
      "+----+------------------------+--------------------------------------------------------------------------------------+\n",
      "+----+-----------+-----------+\n",
      "|    |   Percent | Words     |\n",
      "+====+===========+===========+\n",
      "|  0 |  2.16817  | upon      |\n",
      "+----+-----------+-----------+\n",
      "|  1 |  1.4423   | part      |\n",
      "+----+-----------+-----------+\n",
      "|  2 |  1.32586  | would     |\n",
      "+----+-----------+-----------+\n",
      "|  3 |  1.31328  | price     |\n",
      "+----+-----------+-----------+\n",
      "|  4 |  1.29545  | country   |\n",
      "+----+-----------+-----------+\n",
      "|  5 |  1.26817  | great     |\n",
      "+----+-----------+-----------+\n",
      "|  6 |  1.16223  | one       |\n",
      "+----+-----------+-----------+\n",
      "|  7 |  1.1381   | greater   |\n",
      "+----+-----------+-----------+\n",
      "|  8 |  1.05734  | much      |\n",
      "+----+-----------+-----------+\n",
      "|  9 |  1.03321  | labour    |\n",
      "+----+-----------+-----------+\n",
      "| 10 |  1.03006  | may       |\n",
      "+----+-----------+-----------+\n",
      "| 11 |  1.00803  | trade     |\n",
      "+----+-----------+-----------+\n",
      "| 12 |  0.981811 | produce   |\n",
      "+----+-----------+-----------+\n",
      "| 13 |  0.938805 | must      |\n",
      "+----+-----------+-----------+\n",
      "| 14 |  0.916777 | therefore |\n",
      "+----+-----------+-----------+\n",
      "| 15 |  0.877966 | different |\n",
      "+----+-----------+-----------+\n",
      "| 16 |  0.834959 | quantity  |\n",
      "+----+-----------+-----------+\n",
      "| 17 |  0.828666 | value     |\n",
      "+----+-----------+-----------+\n",
      "| 18 |  0.812931 | people    |\n",
      "+----+-----------+-----------+\n",
      "| 19 |  0.801393 | every     |\n",
      "+----+-----------+-----------+\n",
      "+----+---------------------------------------+------------+\n",
      "|    | Property                              |      Value |\n",
      "+====+=======================================+============+\n",
      "|  0 | Number of Senetences                  | 12032      |\n",
      "+----+---------------------------------------+------------+\n",
      "|  1 | Average Sentence Length in Words      |    32.0769 |\n",
      "+----+---------------------------------------+------------+\n",
      "|  2 | Average Sentence Length in Characters |   185.033  |\n",
      "+----+---------------------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "fp1 = open('pg3300.txt','r')\n",
    "raw1 = fp1.read().replace('\\n', ' ')\n",
    "sents1 = sent_tokenizer.tokenize(raw1)\n",
    "sents1[0]\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = nltk.RegexpTokenizer(r'(?:[A-Z]\\.)+|\\w+-+\\s\\w+|\\w+\\*+\\s\\w+|\\w+|\\d+|\\d+-\\d+|\\w+\\'\\w+')\n",
    "words1 = tokenizer.tokenize(raw1)\n",
    "# words1\n",
    "\n",
    "mp_freqdist1 = nltk.FreqDist(words1)\n",
    "mp_freqdist1.most_common(20)\n",
    "\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "adjust_words1 =[]\n",
    "for w in words1:\n",
    "    # remove stop words and word less than 1 character\n",
    "    if (w.lower() not in stopwords.words('english')) and (len(w) > 1):\n",
    "        # adjust words that are sepeated in two lines, e.g. \"expedi- tion\" to \"expedition\" or \"In* dians\" to \"Indians\"\n",
    "        if re.findall(r'\\w+[-|\\*][\\s+]+\\w+|\\d+\\s+\\d+', w):\n",
    "            adjust_words1.append(w.replace('- ','').replace('* ', ''))\n",
    "        else:\n",
    "            adjust_words1.append(w)\n",
    "# adjust_words1\n",
    "\n",
    "adjust_mp_freqdist1 = nltk.FreqDist(adjust_words1)\n",
    "adjust_mp_freqdist1.most_common(20)\n",
    "\n",
    "\n",
    "\n",
    "number_of_words1 = len(adjust_words1)\n",
    "number_of_unique_words1 = len(set(adjust_words1))\n",
    "average_word_length1 = sum([len(w) for w in adjust_words1]) / number_of_words1\n",
    "maxlen1 = max(len(w) for w in adjust_words1)\n",
    "longest_words1 = [w for w in adjust_words1 if len(w) == maxlen1]\n",
    "\n",
    "df1 = pd.DataFrame({'Property' : [\"Number of Words\", \"Number of Unique Words\" , \"Average Word Length\", \"Longest Word\"],\n",
    "                   'Value' : [number_of_words1, number_of_unique_words1, average_word_length1, longest_words1]})\n",
    "print(tabulate(df1, headers='keys', tablefmt='grid'))\n",
    "\n",
    "most_percent1 = []\n",
    "most_words1 = []\n",
    "for w, f in adjust_mp_freqdist1.most_common(20):\n",
    "    most_words1.append(w)\n",
    "    most_percent1.append(f * 100/number_of_words)\n",
    "\n",
    "df21 = pd.DataFrame({'Words' : most_words1,\n",
    "                   'Percent' : most_percent1})\n",
    "print(tabulate(df21, headers='keys', tablefmt='grid'))\n",
    "\n",
    "capitalized_adjust_words1 = [w for w in adjust_words1 if w.isupper()]\n",
    "captitalized_adjust_mp_freqdist1 = nltk.FreqDist(capitalized_adjust_words1)\n",
    "captitalized_adjust_mp_freqdist1.most_common(20)\n",
    "\n",
    "adjust_sents1 =  [sent.strip() for sent in sents1]\n",
    "number_of_sents1 = len(adjust_sents1)\n",
    "\n",
    "sum_of_words_in_sentence1 = 0\n",
    "for sent in adjust_sents1:\n",
    "    tokenizer11 = nltk.RegexpTokenizer('\\w+|\\w-\\s*\\w')  # This regular expresssion should be revised\n",
    "    words_in_sents1 = tokenizer11.tokenize(sent)\n",
    "    sum_of_words_in_sentence1 += len(words_in_sents1)\n",
    "\n",
    "average_number_words_in_sents1 = sum_of_words_in_sentence1 / number_of_sents1\n",
    "\n",
    "average_number_characters_in_sents1 = sum(len(w) for w in adjust_sents1 ) / number_of_sents1\n",
    "\n",
    "df31 = pd.DataFrame({'Property' : ['Number of Senetences', 'Average Sentence Length in Words', 'Average Sentence Length in Characters'],\n",
    "                   'Value' :[number_of_sents1, average_number_words_in_sents1, average_number_characters_in_sents1]})\n",
    "print(tabulate(df31, headers='keys', tablefmt='grid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "My partners's text is almost as twice as mine in words. Sicne he has added some customized stop words to the stop list, the statics of word count is much different. Based on the examination of my text, I add some regex to remove dashes or asterisks between words to restore the whole word, however, this can't apply to my parnter's text, resulting in wrongly tokenize a whole word into two, as we can see from the calculation of longest word.\n",
    "\n",
    "At sentence level, my partner's text is about one third longer than mine, as well as words and characters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
